{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Sequence to sequence learning for performing number addition\n",
    "\n",
    "**Author:** [Smerity](https://twitter.com/Smerity) and others<br>\n",
    "**Date created:** 2015/08/17<br>\n",
    "**Last modified:** 2020/04/17<br>\n",
    "**Description:** A model that learns to add strings of numbers, e.g. \"535+61\" -> \"596\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Input: \"535+61\"\n",
    "- Output: \"596\"\n",
    "\n",
    "Input may optionally be reversed, which was shown to increase performance in many tasks\n",
    " in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
    "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf).\n",
    "\n",
    "Theoretically, sequence order inversion introduces shorter term dependencies between\n",
    " source and target for this problem.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "For two digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 17:41:29.598391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3752/1046822725.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
      "/tmp/ipykernel_3752/1046822725.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 17:42:24.566429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 17:42:24.568441: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 12)             1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 15s 9ms/step - loss: 1.7644 - accuracy: 0.3538 - val_loss: 1.5648 - val_accuracy: 0.4085\n",
      "1/1 [==============================] - 1s 543ms/step\n",
      "Q 297+987 T 1284 ☒ 1521\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 83+111  T 194  ☒ 221 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 391+979 T 1370 ☒ 1561\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 172+888 T 1060 ☒ 101 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 0+945   T 945  ☒ 995 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 9+444   T 453  ☒ 144 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 187+878 T 1065 ☒ 101 \n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 96+359  T 455  ☒ 601 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 247+832 T 1079 ☒ 101 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 986+43  T 1029 ☒ 902 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3501 - accuracy: 0.4938 - val_loss: 1.1819 - val_accuracy: 0.5515\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Q 5+539   T 544  ☒ 543 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 73+60   T 133  ☑ 133 \n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Q 0+863   T 863  ☑ 863 \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 96+258  T 354  ☒ 330 \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 12+598  T 610  ☒ 600 \n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 416+668 T 1084 ☒ 1101\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 384+54  T 438  ☒ 430 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 49+169  T 218  ☒ 204 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 718+11  T 729  ☒ 732 \n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Q 358+1   T 359  ☒ 346 \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0454 - accuracy: 0.6125 - val_loss: 0.9557 - val_accuracy: 0.6454\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Q 590+873 T 1463 ☒ 1454\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 327+944 T 1271 ☒ 1201\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 578+673 T 1251 ☑ 1251\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Q 797+94  T 891  ☒ 871 \n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Q 52+655  T 707  ☒ 601 \n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 586+228 T 814  ☒ 891 \n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 695+65  T 760  ☒ 751 \n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Q 477+105 T 582  ☒ 591 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 53+37   T 90   ☒ 88  \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 337+62  T 399  ☒ 390 \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8794 - accuracy: 0.6749 - val_loss: 0.8082 - val_accuracy: 0.7063\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 924+81  T 1005 ☒ 1003\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 341+867 T 1208 ☒ 1100\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Q 1+585   T 586  ☒ 589 \n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 517+549 T 1066 ☒ 1051\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Q 540+928 T 1468 ☒ 1451\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Q 77+475  T 552  ☒ 554 \n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Q 3+289   T 292  ☒ 298 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 531+685 T 1216 ☒ 1210\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 15+548  T 563  ☒ 565 \n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Q 653+655 T 1308 ☒ 1300\n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.7563 - accuracy: 0.7231 - val_loss: 0.7111 - val_accuracy: 0.7418\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Q 458+7   T 465  ☒ 464 \n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Q 148+8   T 156  ☒ 154 \n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 493+854 T 1347 ☒ 1342\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Q 46+285  T 331  ☒ 329 \n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Q 359+818 T 1177 ☒ 1179\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Q 140+642 T 782  ☒ 779 \n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 67+143  T 210  ☒ 219 \n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Q 606+499 T 1105 ☒ 1102\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Q 189+40  T 229  ☒ 239 \n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Q 391+55  T 446  ☒ 440 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6748 - accuracy: 0.7551 - val_loss: 0.6412 - val_accuracy: 0.7686\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 208+722 T 930  ☒ 935 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 4+415   T 419  ☑ 419 \n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 583+19  T 602  ☒ 600 \n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Q 22+518  T 540  ☒ 539 \n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Q 426+515 T 941  ☒ 944 \n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Q 27+125  T 152  ☒ 159 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 120+1   T 121  ☒ 111 \n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 22+518  T 540  ☒ 539 \n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Q 30+17   T 47   ☒ 41  \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 545+29  T 574  ☒ 573 \n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5727 - accuracy: 0.7929 - val_loss: 0.4854 - val_accuracy: 0.8237\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 4+521   T 525  ☒ 526 \n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 6+17    T 23   ☒ 12  \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 4+962   T 966  ☒ 967 \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 920+17  T 937  ☒ 936 \n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Q 347+162 T 509  ☒ 500 \n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 487+309 T 796  ☑ 796 \n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Q 55+166  T 221  ☒ 211 \n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Q 104+181 T 285  ☒ 283 \n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Q 77+439  T 516  ☒ 514 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 81+337  T 418  ☒ 419 \n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.3595 - accuracy: 0.8787 - val_loss: 0.2799 - val_accuracy: 0.9162\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 97+45   T 142  ☑ 142 \n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 73+187  T 260  ☑ 260 \n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Q 743+857 T 1600 ☒ 1500\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Q 43+33   T 76   ☑ 76  \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 35+648  T 683  ☑ 683 \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 96+870  T 966  ☑ 966 \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 409+894 T 1303 ☒ 1204\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 562+3   T 565  ☑ 565 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 58+173  T 231  ☑ 231 \n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Q 327+944 T 1271 ☒ 1272\n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.2098 - accuracy: 0.9421 - val_loss: 0.1845 - val_accuracy: 0.9512\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 206+44  T 250  ☑ 250 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 31+16   T 47   ☑ 47  \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 2+586   T 588  ☑ 588 \n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Q 91+622  T 713  ☑ 713 \n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Q 2+414   T 416  ☑ 416 \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 278+179 T 457  ☒ 467 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 471+797 T 1268 ☑ 1268\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 450+662 T 1112 ☑ 1112\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 591+870 T 1461 ☒ 1462\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 400+391 T 791  ☒ 792 \n",
      "\n",
      "Iteration 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1455 - accuracy: 0.9628 - val_loss: 0.1073 - val_accuracy: 0.9744\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 310+477 T 787  ☑ 787 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 337+97  T 434  ☑ 434 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 653+3   T 656  ☑ 656 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 169+95  T 264  ☑ 264 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 16+250  T 266  ☑ 266 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 49+169  T 218  ☑ 218 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 0+454   T 454  ☑ 454 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 333+475 T 808  ☒ 708 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 435+242 T 677  ☑ 677 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 436+54  T 490  ☑ 490 \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.1063 - accuracy: 0.9726 - val_loss: 0.0924 - val_accuracy: 0.9768\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 16+42   T 58   ☑ 58  \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 968+866 T 1834 ☑ 1834\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 438+237 T 675  ☑ 675 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 58+576  T 634  ☑ 634 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 663+330 T 993  ☑ 993 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 37+181  T 218  ☑ 218 \n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Q 5+124   T 129  ☑ 129 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 95+33   T 128  ☑ 128 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 336+185 T 521  ☑ 521 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 808+425 T 1233 ☑ 1233\n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0819 - accuracy: 0.9797 - val_loss: 0.1236 - val_accuracy: 0.9589\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 218+568 T 786  ☑ 786 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 650+37  T 687  ☑ 687 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 86+92   T 178  ☑ 178 \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 575+185 T 760  ☑ 760 \n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Q 76+942  T 1018 ☑ 1018\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 823+15  T 838  ☑ 838 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 96+258  T 354  ☑ 354 \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 6+680   T 686  ☑ 686 \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Q 905+466 T 1371 ☑ 1371\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 206+170 T 376  ☑ 376 \n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0548 - accuracy: 0.9878 - val_loss: 0.0698 - val_accuracy: 0.9804\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 54+148  T 202  ☑ 202 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 0+421   T 421  ☑ 421 \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 723+3   T 726  ☑ 726 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 59+873  T 932  ☑ 932 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 60+27   T 87   ☑ 87  \n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Q 744+586 T 1330 ☑ 1330\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 87+249  T 336  ☑ 336 \n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 140+74  T 214  ☑ 214 \n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Q 440+574 T 1014 ☑ 1014\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 15+314  T 329  ☑ 329 \n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0624 - accuracy: 0.9840 - val_loss: 0.0371 - val_accuracy: 0.9922\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Q 61+536  T 597  ☑ 597 \n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Q 477+955 T 1432 ☑ 1432\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Q 59+324  T 383  ☑ 383 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 381+90  T 471  ☑ 471 \n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Q 489+23  T 512  ☑ 512 \n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Q 235+929 T 1164 ☒ 1154\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 738+481 T 1219 ☑ 1219\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 115+710 T 825  ☒ 824 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 248+700 T 948  ☑ 948 \n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 194+862 T 1056 ☑ 1056\n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0398 - accuracy: 0.9912 - val_loss: 0.0270 - val_accuracy: 0.9941\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 216+64  T 280  ☑ 280 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 20+532  T 552  ☑ 552 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 2+68    T 70   ☑ 70  \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 549+129 T 678  ☑ 678 \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Q 61+704  T 765  ☑ 765 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 484+415 T 899  ☒ 999 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 60+375  T 435  ☑ 435 \n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Q 959+892 T 1851 ☑ 1851\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Q 293+746 T 1039 ☑ 1039\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 47+570  T 617  ☑ 617 \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0391 - accuracy: 0.9899 - val_loss: 0.0289 - val_accuracy: 0.9929\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Q 974+204 T 1178 ☑ 1178\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 822+769 T 1591 ☑ 1591\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 7+767   T 774  ☑ 774 \n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Q 835+84  T 919  ☑ 919 \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 932+2   T 934  ☑ 934 \n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Q 190+538 T 728  ☑ 728 \n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Q 222+53  T 275  ☑ 275 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 45+41   T 86   ☑ 86  \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 97+977  T 1074 ☑ 1074\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 97+815  T 912  ☑ 912 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0389 - accuracy: 0.9905 - val_loss: 0.0221 - val_accuracy: 0.9948\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Q 169+46  T 215  ☑ 215 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 9+774   T 783  ☑ 783 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 51+38   T 89   ☑ 89  \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 815+4   T 819  ☑ 819 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 4+342   T 346  ☑ 346 \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 343+85  T 428  ☑ 428 \n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Q 108+718 T 826  ☒ 816 \n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 473+30  T 503  ☑ 503 \n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 80+129  T 209  ☑ 209 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 726+7   T 733  ☑ 733 \n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0344 - accuracy: 0.9908 - val_loss: 0.0180 - val_accuracy: 0.9967\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 85+48   T 133  ☑ 133 \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 73+474  T 547  ☑ 547 \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 108+52  T 160  ☑ 160 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 128+731 T 859  ☑ 859 \n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 347+162 T 509  ☑ 509 \n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Q 230+30  T 260  ☑ 260 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 438+0   T 438  ☑ 438 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 77+82   T 159  ☑ 159 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 89+77   T 166  ☑ 166 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 140+74  T 214  ☑ 214 \n",
      "\n",
      "Iteration 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 0.0154 - val_accuracy: 0.9977\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 729+660 T 1389 ☑ 1389\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 854+59  T 913  ☑ 913 \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 891+188 T 1079 ☑ 1079\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 486+237 T 723  ☑ 723 \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 451+80  T 531  ☑ 531 \n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Q 1+388   T 389  ☑ 389 \n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Q 683+597 T 1280 ☑ 1280\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Q 695+442 T 1137 ☑ 1137\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 94+790  T 884  ☑ 884 \n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Q 60+747  T 807  ☑ 807 \n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0221 - val_accuracy: 0.9946\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 496+63  T 559  ☑ 559 \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Q 607+979 T 1586 ☑ 1586\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 819+634 T 1453 ☑ 1453\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 374+3   T 377  ☑ 377 \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 689+434 T 1123 ☑ 1123\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 29+82   T 111  ☑ 111 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 94+88   T 182  ☑ 182 \n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Q 83+415  T 498  ☑ 498 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 57+208  T 265  ☑ 265 \n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Q 83+448  T 531  ☑ 531 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.0238 - val_accuracy: 0.9939\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 370+250 T 620  ☑ 620 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 851+56  T 907  ☑ 907 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 986+43  T 1029 ☑ 1029\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 318+294 T 612  ☑ 612 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 25+157  T 182  ☑ 182 \n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 897+482 T 1379 ☑ 1379\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 339+299 T 638  ☑ 638 \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 8+242   T 250  ☑ 250 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 433+17  T 450  ☑ 450 \n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 620+4   T 624  ☑ 624 \n",
      "\n",
      "Iteration 22\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.0901 - val_accuracy: 0.9706\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Q 488+365 T 853  ☑ 853 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 325+509 T 834  ☑ 834 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 91+84   T 175  ☑ 175 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 77+475  T 552  ☑ 552 \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 87+46   T 133  ☑ 133 \n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 624+42  T 666  ☑ 666 \n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Q 158+36  T 194  ☑ 194 \n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 51+28   T 79   ☑ 79  \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 16+18   T 34   ☑ 34  \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 30+165  T 195  ☑ 195 \n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 0.0147 - val_accuracy: 0.9963\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Q 91+42   T 133  ☑ 133 \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 638+9   T 647  ☑ 647 \n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Q 18+42   T 60   ☑ 60  \n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Q 4+719   T 723  ☑ 723 \n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Q 611+460 T 1071 ☑ 1071\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 294+979 T 1273 ☑ 1273\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 479+291 T 770  ☑ 770 \n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 462+29  T 491  ☑ 491 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 169+50  T 219  ☑ 219 \n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 250+6   T 256  ☑ 256 \n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0273 - accuracy: 0.9923 - val_loss: 0.0317 - val_accuracy: 0.9908\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 88+402  T 490  ☑ 490 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 30+280  T 310  ☑ 310 \n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Q 885+728 T 1613 ☑ 1613\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 17+312  T 329  ☑ 329 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 570+50  T 620  ☑ 620 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 636+136 T 772  ☑ 772 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 47+83   T 130  ☑ 130 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 73+679  T 752  ☑ 752 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 48+648  T 696  ☑ 696 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 110+349 T 459  ☑ 459 \n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 483+723 T 1206 ☑ 1206\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 391+507 T 898  ☑ 898 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 32+600  T 632  ☑ 632 \n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 592+111 T 703  ☑ 703 \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 704+619 T 1323 ☑ 1323\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 60+938  T 998  ☑ 998 \n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Q 687+50  T 737  ☑ 737 \n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Q 90+428  T 518  ☑ 518 \n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 581+86  T 667  ☑ 667 \n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Q 435+234 T 669  ☑ 669 \n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.0129 - val_accuracy: 0.9969\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 395+638 T 1033 ☑ 1033\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Q 8+305   T 313  ☑ 313 \n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Q 189+8   T 197  ☑ 197 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 524+53  T 577  ☑ 577 \n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Q 3+236   T 239  ☑ 239 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 81+894  T 975  ☑ 975 \n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 31+79   T 110  ☑ 110 \n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Q 93+419  T 512  ☑ 512 \n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Q 359+22  T 381  ☑ 381 \n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Q 5+77    T 82   ☑ 82  \n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0332 - val_accuracy: 0.9900\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 242+19  T 261  ☑ 261 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 45+74   T 119  ☑ 119 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 374+41  T 415  ☑ 415 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 118+798 T 916  ☑ 916 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 944+45  T 989  ☑ 989 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 325+99  T 424  ☑ 424 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 336+185 T 521  ☑ 521 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 22+990  T 1012 ☑ 1012\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 896+4   T 900  ☑ 900 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 913+72  T 985  ☑ 985 \n",
      "\n",
      "Iteration 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9881\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 131+92  T 223  ☑ 223 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 556+73  T 629  ☑ 629 \n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 370+8   T 378  ☑ 378 \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Q 91+394  T 485  ☑ 485 \n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Q 25+48   T 73   ☑ 73  \n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Q 349+204 T 553  ☑ 553 \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Q 179+22  T 201  ☑ 201 \n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Q 885+728 T 1613 ☑ 1613\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Q 387+15  T 402  ☑ 402 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 190+21  T 211  ☑ 211 \n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Q 472+36  T 508  ☑ 508 \n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Q 48+879  T 927  ☑ 927 \n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Q 879+51  T 930  ☑ 930 \n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Q 71+39   T 110  ☑ 110 \n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Q 91+407  T 498  ☑ 498 \n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Q 826+85  T 911  ☑ 911 \n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Q 2+860   T 862  ☑ 862 \n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Q 992+740 T 1732 ☑ 1732\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Q 69+41   T 110  ☑ 110 \n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 534+942 T 1476 ☑ 1476\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "You'll get to 99+% validation accuracy after ~30 epochs.\n",
    "\n",
    "Example available on HuggingFace.\n",
    "\n",
    "| Trained Model | Demo |\n",
    "| :--: | :--: |\n",
    "| [![Generic badge](https://img.shields.io/badge/🤗%20Model-Addition%20LSTM-black.svg)](https://huggingface.co/keras-io/addition-lstm) | [![Generic badge](https://img.shields.io/badge/🤗%20Spaces-Addition%20LSTM-black.svg)](https://huggingface.co/spaces/keras-io/addition-lstm) |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "addition_rnn",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
